{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d815b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ[\"LANGCHAIN_TRACKING_V2\"] = 'true'\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b6965c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e483aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diff kind of model in openai, gpt4\n",
    "llm= ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddade79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Generative AI refers to a branch of artificial intelligence that focuses on creating systems capable of generating content. This content can include text, images, music, video, and more. The defining feature of generative AI is its ability to produce new, previously unseen data that resembles the training data it was exposed to. These systems are typically built using models that learn patterns from large datasets and then use these patterns to generate similar content.\\n\\nSome of the key technologies and techniques used in generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs):** A framework where two neural networks, a generator and a discriminator, are trained together. The generator creates content, and the discriminator evaluates it, pushing the generator to create more realistic outputs.\\n\\n2. **Variational Autoencoders (VAEs):** A type of neural network that learns to encode input data into a compressed latent space and then decode it back to the original data, enabling the generation of new data samples.\\n\\n3. **Transformer Models:** Architectures like GPT (Generative Pre-trained Transformer) leverage self-attention mechanisms to generate coherent and contextually relevant text.\\n\\n4. **Recurrent Neural Networks (RNNs):** Especially those with Long Short-Term Memory (LSTM) units, have been used for generating sequences like music and text by remembering long-term dependencies.\\n\\nGenerative AI has a wide range of applications, including:\\n\\n- Text generation, such as chatbots and content creation.\\n- Image synthesis and style transfer.\\n- Music composition and sound generation.\\n- Game and virtual environment design.\\n- Drug discovery and molecular generation in scientific research.\\n\\nWhile powerful, generative AI also raises various ethical and societal concerns, such as the potential for misinformation, deepfakes, and intellectual property issues, requiring careful consideration and regulatory measures.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 362, 'prompt_tokens': 13, 'total_tokens': 375, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BuDHte7vLlvTMs9CUl22Uvfu4YTfW', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--0097a949-5468-44a9-a046-e6477f838774-0', usage_metadata={'input_tokens': 13, 'output_tokens': 362, 'total_tokens': 375, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input and response from LLM\n",
    "llm.invoke(\"What is generative Ai?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d9ba695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current key: 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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current key:\", os.getenv(\"OPENAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dff9007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chatprompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert Ai engineer. Provide me answers based on questions\"),\n",
    "    (\"user\", \"{input}\")\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b85c9f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a tool developed by LangChain to provide developers with advanced capabilities for debugging and testing applications that are built using language models. It is particularly useful for tracking model outputs, evaluating performance across various metrics, and refining the behavior of language models within an application. Langsmith allows developers to gain better insights into how their applications interact with language models, enabling them to diagnose issues and improve overall application performance. This tool supports features like logging, tracing, and analyzing responses from language models to help ensure more reliable and effective use of AI in applications.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 109, 'prompt_tokens': 32, 'total_tokens': 141, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-BuDc2oi6ZjKUqzrQrrK0AbOCWRidN', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--a26f133e-a7a7-4c12-9d66-b6d04a75ff4b-0' usage_metadata={'input_tokens': 32, 'output_tokens': 109, 'total_tokens': 141, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt|llm\n",
    "\n",
    "response= chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd69a3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d38e300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a tool developed by LangChain that helps developers evaluate, test, and optimize applications, particularly those that work with language models. It allows for the logging and analysis of applications to better understand their performance, pinpoint areas of improvement, and iterate on design. LangSmith facilitates both manual and automated testing, supports tracing to visualize where an application might be encountering issues, and enables fine-tuning and optimization of workflows. It's designed to enhance the productivity of developers working with complex language models by providing insights and tools to refine their applications efficiently.\n"
     ]
    }
   ],
   "source": [
    "#string output parser-- getting message from llm and how we display it\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser= StrOutputParser()\n",
    "chain= prompt|llm|output_parser\n",
    "response = chain.invoke({\"input\":\"Can you tell me about LangSmith?\"})\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc333bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##one website has some content and we are going to extarct information from the website and then scrap the content. Divide text in chunks -- vector--vectordb-- llm for output\n",
    "url = \"https://learn.microsoft.com/en-us/intune/intune-service/fundamentals/what-is-intune\"\n",
    "\n",
    "#data ingestion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
